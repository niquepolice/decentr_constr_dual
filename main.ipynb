{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5005dbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rc('text', usetex=True)\n",
    "matplotlib.rcParams['text.latex.preamble']=r\"\\usepackage{amsmath}\"\n",
    "\n",
    "\n",
    "from stuff import *\n",
    "from utils import *\n",
    "float_formatter = lambda x: \"%.2e\" % x\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7705000",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "iters = 1000\n",
    "np.random.seed(42)\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "model_params = dict(nodes=5, dim=40, B_rank=1)#, graph=\"erdos-renyi\", edge_prob=0.3)\n",
    "model = Model(**model_params)\n",
    "\n",
    "mu_x, mu_xy, L_x, L_xy = model.get_mu_L()\n",
    "\n",
    "t_start = time()\n",
    "x_res, f_err, cons_err = APDG(iters, model)\n",
    "print(f\"\\ntime APDG: {time() - t_start}\\n\")\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(f_err, label='APDG')\n",
    "plt.title('$|F(\\\\boldsymbol{x}^k) -F^*|$')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(cons_err, label='APDG')\n",
    "plt.title('$||\\\\boldsymbol{Ax}^k||$')\n",
    "plt.yscale('log')\n",
    "\n",
    "t_start = time()\n",
    "x_res, f_err, cons_err = GDAM(iters, model)\n",
    "print(f\"\\ntime GDAM: {time() - t_start}\\n\")\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(f_err, label='Globally Dual')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(cons_err, label='Globally Dual')\n",
    "plt.legend()\n",
    "\n",
    "t_start = time()\n",
    "x_res, f_err, cons_err = LDAM(iters, model)\n",
    "print(f\"\\ntime LDAM: {time() - t_start}\\n\")\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(f_err, label='Locally Dual')\n",
    "plt.legend()\n",
    "plt.xlabel('Iteration number')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(cons_err, label='Locally Dual')\n",
    "plt.legend()\n",
    "plt.xlabel('Iteration number')\n",
    "\n",
    "# plt.savefig(\"n10_d100.eps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9afec4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "iters=4000\n",
    "repeat = 10 \n",
    "t_apdm, t_gdam, t_ldam = 0, 0, 0\n",
    "it_apdm, it_gdam, it_ldam = 0, 0, 0\n",
    "limit_apdm, limit_gdam, limit_ldam = 0, 0, 0\n",
    "\n",
    "accuracy = 1e-2\n",
    "\n",
    "for _ in range(repeat):\n",
    "    model = Model(**model_params)\n",
    "    t_start = time()\n",
    "    x_res, f_err, cons_err = APDG(iters, model, use_crit=True, accuracy=accuracy)\n",
    "    t_apdm += time() - t_start\n",
    "    it = (f_err > 0).sum()  # error arrays initialized as np.zeros()\n",
    "    it_apdm += it\n",
    "    limit_apdm += (it >= iters)\n",
    "    print(\"iters, \", it, \"total excessions:\", limit_apdm)\n",
    "    if it >= iters:\n",
    "        plt.plot(f_err, label=\"apdm\" + str(_))\n",
    "        plt.yscale(\"log\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    t_start = time()\n",
    "    x_res, f_err, cons_err = GDAM(iters, model, use_crit=True, accuracy=accuracy)\n",
    "    t_gdam += time() - t_start\n",
    "    it = (f_err > 0).sum()  # error arrays initialized as np.zeros()\n",
    "    it_gdam += it\n",
    "    limit_gdam += (it >= iters)\n",
    "    print(\"iters, \", it, \"total excessions:\", limit_gdam)\n",
    "    if it >= iters:\n",
    "        plt.plot(f_err, label=\"gdam\" + str(_))\n",
    "        plt.yscale(\"log\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    t_start = time()\n",
    "    x_res, f_err, cons_err = LDAM(iters, model, use_crit=True, accuracy=accuracy)\n",
    "    t_ldam += time() - t_start\n",
    "    it = (f_err > 0).sum()  # error arrays initialized as np.zeros()\n",
    "    it_ldam += it\n",
    "    limit_ldam += (it >= iters)\n",
    "    print(\"iters, \", it, \"total excessions:\", limit_ldam)\n",
    "    if it >= iters:\n",
    "        plt.plot(f_err, label=\"ldam\" + str(_))\n",
    "        plt.yscale(\"log\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "print(f\"\\ntime APDG (crit): {t_apdm / repeat}, iters: {it_apdm / repeat}, excessions: {limit_apdm}\\n\")  \n",
    "print(f\"\\ntime GDAM (crit): {t_gdam / repeat}, iters: {it_gdam / repeat}, excessions: {limit_gdam}\\n\")\n",
    "print(f\"\\ntime LDAM (crit): {t_ldam / repeat}, iters: {it_ldam / repeat}, excessions: {limit_ldam}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feb75e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
