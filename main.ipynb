{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5005dbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rc('text', usetex=True)\n",
    "matplotlib.rcParams['text.latex.preamble']=r\"\\usepackage{amsmath}\"\n",
    "\n",
    "\n",
    "from stuff import *\n",
    "from utils import *\n",
    "float_formatter = lambda x: \"%.2e\" % x\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from time import time\n",
    "import cProfile\n",
    "import pstats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7705000",
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = 1000\n",
    "np.random.seed(42)\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "model_params = dict(nodes=10, dim=100, B_rank=1, graph=\"erdos-renyi\", edge_prob=0.2)\n",
    "model = Model(**model_params)\n",
    "\n",
    "mu_x, mu_xy, L_x, L_xy = model.get_mu_L()\n",
    "\n",
    "t_start = time()\n",
    "x_res, f_err, cons_err = APDM(iters, model)\n",
    "print(f\"\\ntime APDM: {time() - t_start}\\n\")\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(f_err, label='APDM')\n",
    "plt.title('$|F(\\\\boldsymbol{x}^k) -F^*|$')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(cons_err, label='APDM')\n",
    "plt.title('$||\\\\boldsymbol{Ax}^k||$')\n",
    "plt.yscale('log')\n",
    "\n",
    "C = 2.5  # big O const\n",
    "N = np.arange(iters)\n",
    "plt.subplot(121)\n",
    "first_guy = (L_x / mu_x)**0.5 * L_xy / mu_xy\n",
    "second_guy = (L_xy / mu_xy) ** 2\n",
    "rate_const = max(first_guy, second_guy)\n",
    "print(\"first_guy\", first_guy, \"second_guy\", second_guy, \"rate_const\", rate_const)\n",
    "\n",
    "# plt.plot(f_err[0] * np.exp(-N / (C * rate_const)), label='APDM upper')\n",
    "\n",
    "\n",
    "\n",
    "# x_res, f_err, cons_err = LDM(iters, model)\n",
    "\n",
    "# plt.subplot(121)\n",
    "# plt.plot(f_err, label='locally dual nonacc')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(122)\n",
    "# plt.plot(cons_err, label='locally dual nonacc')\n",
    "# plt.legend()\n",
    "\n",
    "\n",
    "# x_res, f_err, cons_err = GDM(iters, model)\n",
    "\n",
    "# plt.subplot(121)\n",
    "# plt.plot(f_err, label='globally dual nonacc')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(122)\n",
    "# plt.plot(cons_err, label='globally dual nonacc')\n",
    "# plt.legend()\n",
    "\n",
    "t_start = time()\n",
    "x_res, f_err, cons_err = GDAM(iters, model)\n",
    "print(f\"\\ntime GDAM: {time() - t_start}\\n\")\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(f_err, label='Globally Dual')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(cons_err, label='Globally Dual')\n",
    "plt.legend()\n",
    "\n",
    "t_start = time()\n",
    "x_res, f_err, cons_err = LDAM(iters, model)\n",
    "print(f\"\\ntime LDAM: {time() - t_start}\\n\")\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(f_err, label='Locally Dual')\n",
    "plt.legend()\n",
    "plt.xlabel('Iteration number')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(cons_err, label='Locally Dual')\n",
    "plt.legend()\n",
    "plt.xlabel('Iteration number')\n",
    "\n",
    "plt.savefig(\"n10_d100.eps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8b7370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9afec4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "iters=4000\n",
    "repeat = 10 \n",
    "t_apdm, t_gdam, t_ldam = 0, 0, 0\n",
    "it_apdm, it_gdam, it_ldam = 0, 0, 0\n",
    "for _ in range(repeat):\n",
    "    model = Model(**model_params)\n",
    "    t_start = time()\n",
    "    x_res, f_err, cons_err = APDM(iters, model, use_crit=True)\n",
    "    t_apdm += time() - t_start\n",
    "    it_apdm += (f_err > 0).sum()  # error arrays initialized as np.zeros()\n",
    "    \n",
    "    t_start = time()\n",
    "    x_res, f_err, cons_err = GDAM(iters, model, use_crit=True)\n",
    "    t_gdam += time() - t_start\n",
    "    it_gdam += (f_err > 0).sum() \n",
    "    \n",
    "    \n",
    "    t_start = time()\n",
    "    x_res, f_err, cons_err = LDAM(iters, model, use_crit=True)\n",
    "    t_ldam += time() - t_start\n",
    "    it_ldam += (f_err > 0).sum() \n",
    "    \n",
    "print(f\"\\ntime APDM (crit): {t_apdm / repeat}, iters: {it_apdm / repeat}\\n\")  \n",
    "print(f\"\\ntime GDAM (crit): {t_gdam / repeat}, iters: {it_gdam / repeat}\\n\")\n",
    "print(f\"\\ntime LDAM (crit): {t_ldam / repeat}, iters: {it_ldam / repeat}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fa1dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "APDM(iters, model)\n",
    "profiler.disable()\n",
    "stats = pstats.Stats(profiler).sort_stats('cumtime')\n",
    "stats.print_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d699f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "GDAM(iters, model)\n",
    "profiler.disable()\n",
    "stats = pstats.Stats(profiler).sort_stats('cumtime')\n",
    "stats.print_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d596713",
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = 1000\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "model = Model(nodes=4, dim=15)\n",
    "\n",
    "\n",
    "params = list(get_apdm_params(model))\n",
    "x_res, f_err, cons_err = APDM(iters, model, params)\n",
    "\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(f_err, label=f'APDM, auto')\n",
    "plt.title('$|f -f^*|$')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(cons_err, label=f'APDM, auto')\n",
    "plt.title('$||Ax||$')\n",
    "plt.yscale('log')\n",
    "\n",
    "\n",
    "params = list(get_apdm_params(model))\n",
    "\n",
    "x_params, y_params = params\n",
    "eta_x, alpha_x, beta_x, tau_x, sigma_x = x_params\n",
    "theta, eta_y, alpha_y, beta_y, tau_y, sigma_y = y_params\n",
    "\n",
    "# eta_x *= 2 \n",
    "# eta_y *= 2 \n",
    "# theta=0.999\n",
    "# sigma_x = 0.9\n",
    "# sigma_y = 0.5\n",
    "beta_x = 0.0001\n",
    "beta_y = 0.1\n",
    "\n",
    "x_params = eta_x, alpha_x, beta_x, tau_x, sigma_x\n",
    "y_params = theta, eta_y, alpha_y, beta_y, tau_y, sigma_y\n",
    "\n",
    "x_res, f_err, cons_err = APDM(iters, model, (x_params, y_params))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(f_err, label=f'APDM, manual params')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(cons_err, label=f'APDM, manual params')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe16459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M = model.A.T @ model.A\n",
    "from numpy import polynomial as P\n",
    "# np.random.seed(42)\n",
    "M = np.random.random((3,3))\n",
    "M = M.T @ M\n",
    "\n",
    "chi = lambda M: utils.lambda_max(M) / utils.lambda_min_plus(M)\n",
    "gamma = 1 / chi(M)\n",
    "K = int(1 / gamma**0.5 )\n",
    "\n",
    "print(\"chi\", 1/gamma, \"pol_degree\", K)\n",
    "Tk = P.Chebyshev.basis(K)\n",
    "Tk = Tk.convert(kind=P.Polynomial)  # move to power basis\n",
    "\n",
    "# print(\"Tk coefs\", Tk.coef)\n",
    "c2 = (1 + gamma) / (1 - gamma) \n",
    "Pk = 1 - Tk(P.Polynomial([c2, -c2])) / Tk(c2)\n",
    "\n",
    "# Pk_coefs = np.polynomial.chebyshev.cheb2poly(Pk.coef)\n",
    "# print(\"Pk coefs\", Pk.coef)\n",
    "\n",
    "# powers = np.array([np.linalg.matrix_power(M, i) for i in range(len(Pk.coef))])\n",
    "powers = [np.eye(M.shape[0])]\n",
    "for i in range(1, len(Pk.coef)):\n",
    "    powers.append(powers[-1] @ M)\n",
    "    \n",
    "M_ = (powers * Pk.coef[:, np.newaxis, np.newaxis]).sum(axis=0)\n",
    "\n",
    "print(chi(M_))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc9d7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmax, lminp = utils.lambda_max(M), utils.lambda_min_plus(M)\n",
    "print(lmax, lminp )\n",
    "diff = lmax - lminp\n",
    "lams = np.linspace(lminp - diff / 100, lmax + diff / 100, 100)\n",
    "plt.scatter(lminp, Pk(lminp))\n",
    "plt.scatter(lmax, Pk(lmax))\n",
    "print(Pk(lmax) / Pk(lminp))\n",
    "# xx, yy = Pk.linspace()\n",
    "vals = [Pk(lam) for lam in lams]\n",
    "plt.plot(lams, vals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
